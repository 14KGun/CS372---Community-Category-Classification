{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import random\n",
    "import spacy\n",
    "import nltk\n",
    "\n",
    "crawledDataSetNames = ['dataset-reddit-business.csv', 'dataset-reddit-entertainment.csv', \n",
    "'dataset-reddit-parenting.csv', 'dataset-reddit-politics.csv', \n",
    "'dataset-reddit-sports.csv', 'dataset-reddit-travel.csv']\n",
    "\n",
    "categories = ['business', 'entertainment', 'parenting', 'politics', 'sports', 'travel']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read csv and concat title and content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text       category\n",
      "0     Fox News is wrong, Star Trek has always been \"...  entertainment\n",
      "1     Chris Cuomo fired after CNN learned of alleged...  entertainment\n",
      "2      Judge Terminates Britney Spears Conservatorship   entertainment\n",
      "3     Poll finds ‘Jeopardy!’ fans overwhelmingly wan...  entertainment\n",
      "4     More Republicans have died of covid-19. Does t...       politics\n",
      "...                                                 ...            ...\n",
      "2035  Republicans warn Justice Department probe of T...       politics\n",
      "2036  South Park Mocks Vladimir Putin and Addresses ...  entertainment\n",
      "2037  Ryan Reynolds Taking A Break From Acting After...  entertainment\n",
      "2038  Quentin Tarantino pitches Rambo: First Blood r...  entertainment\n",
      "2039  Why Can’t Democrats Make GOP Extremism a Campa...       politics\n",
      "\n",
      "[2040 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.DataFrame(columns = {'text','category'})\n",
    "for crawledDataSetName in crawledDataSetNames:\n",
    "    df = pd.read_csv('./dataset/%s'%crawledDataSetName)\n",
    "    \n",
    "    #replace Nan to empty string\n",
    "    df = df.fillna('')\n",
    "\n",
    "    #'titleAndContent' Column is concat of 'title' and 'content'\n",
    "    df['text']=df['title']+' '+df['content']\n",
    "    dataset = pd.concat([dataset, df[['text', 'category']]])\n",
    "\n",
    "#shuffle row\n",
    "dataset=dataset.sample(frac=1).reset_index(drop=True)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text       category\n",
      "0     [fox, news, is, wrong, star, trek, has, always...  entertainment\n",
      "1     [chris, cuomo, fired, after, cnn, learned, of,...  entertainment\n",
      "2     [judge, terminates, britney, spears, conservat...  entertainment\n",
      "3     [poll, finds, jeopardy, fans, overwhelmingly, ...  entertainment\n",
      "4     [more, republicans, have, died, of, does, that...       politics\n",
      "...                                                 ...            ...\n",
      "2035  [republicans, warn, justice, department, probe...       politics\n",
      "2036  [south, park, mocks, vladimir, putin, and, add...  entertainment\n",
      "2037  [ryan, reynolds, taking, a, break, from, actin...  entertainment\n",
      "2038  [quentin, tarantino, pitches, rambo, first, bl...  entertainment\n",
      "2039  [why, can, t, democrats, make, gop, extremism,...       politics\n",
      "\n",
      "[2040 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "#make all characters to lower case\n",
    "dataset['text']=dataset['text'].apply(lambda x: str.lower(x))\n",
    "\n",
    "#word tokenization\n",
    "dataset['text'] = dataset['text'].apply(lambda x: word_tokenize(x))\n",
    "\n",
    "#delete stopwords and punctuation\n",
    "stopwordList = set(stopwords.words('english') + list(string.punctuation))\n",
    "dataset['text'] = dataset['text'].apply(lambda x: list(word for word in x if word.isalpha()))\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make bag of words column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...\n",
      "1       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...\n",
      "2       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "3       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "4       [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "                              ...                        \n",
      "2035    [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...\n",
      "2036    [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "2037    [2, 1, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, ...\n",
      "2038    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...\n",
      "2039    [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "Name: bagOfWords, Length: 2040, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "#the number of words to use for training\n",
    "numOfFeatureWords = 1000\n",
    "\n",
    "allTextList = sum(dataset['text'].tolist(),[])\n",
    "fdist = FreqDist(allTextList)\n",
    "wordDict = list(word for word, freq in fdist.most_common(numOfFeatureWords))\n",
    "def bagOfWords(tokens):\n",
    "    d = defaultdict(int,{ word:0 for word in wordDict })\n",
    "    for token in tokens:\n",
    "        d[token]+=1\n",
    "    ret = []\n",
    "    for key, val in d.items():\n",
    "        ret.append(val)\n",
    "    return ret[:numOfFeatureWords]\n",
    "\n",
    "dataset['bagOfWords'] = dataset['text'].apply(lambda x: bagOfWords(x))\n",
    "\n",
    "print(dataset['bagOfWords'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add column of one hot encoding for category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       {'business': False, 'entertainment': True, 'pa...\n",
      "1       {'business': False, 'entertainment': True, 'pa...\n",
      "2       {'business': False, 'entertainment': True, 'pa...\n",
      "3       {'business': False, 'entertainment': True, 'pa...\n",
      "4       {'business': False, 'entertainment': False, 'p...\n",
      "                              ...                        \n",
      "2035    {'business': False, 'entertainment': False, 'p...\n",
      "2036    {'business': False, 'entertainment': True, 'pa...\n",
      "2037    {'business': False, 'entertainment': True, 'pa...\n",
      "2038    {'business': False, 'entertainment': True, 'pa...\n",
      "2039    {'business': False, 'entertainment': False, 'p...\n",
      "Name: labels, Length: 2040, dtype: object\n"
     ]
    }
   ],
   "source": [
    "dataset['labels'] = dataset['category'].apply(lambda x: dict(defaultdict(bool,{ category: category == x for category in categories })))\n",
    "print(dataset['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "divide trainset and testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainSize:  1428\n",
      "testSize:  612\n",
      "1428\n",
      "612\n"
     ]
    }
   ],
   "source": [
    "trainSplit = 0.7\n",
    "testSplit = 0.3\n",
    "\n",
    "datasetSize = dataset.shape[0]\n",
    "\n",
    "trainSize = int(datasetSize * trainSplit)\n",
    "testSize = int(datasetSize * testSplit)\n",
    "\n",
    "print('trainSize: ', trainSize)\n",
    "print('testSize: ', testSize)\n",
    "\n",
    "trainSet = dataset.iloc[:trainSize, :]\n",
    "testSet = dataset.iloc[trainSize:, :]\n",
    "\n",
    "print(trainSet.shape[0])\n",
    "print(testSet.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build a Bag of Words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1428, 1000) (1428,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "import numpy as np\n",
    "classifier = GaussianNB()\n",
    "trainX = np.array(trainSet['bagOfWords'].tolist())\n",
    "trainY = np.array(trainSet['category'].tolist())\n",
    "print(trainX.shape, trainY.shape)\n",
    "classifier.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(612, 1000) (612,)\n",
      "['politics' 'politics' 'politics' 'politics' 'entertainment' 'politics'\n",
      " 'politics' 'entertainment' 'politics' 'politics' 'politics'\n",
      " 'entertainment' 'politics' 'politics' 'politics' 'entertainment'\n",
      " 'entertainment' 'politics' 'politics' 'entertainment' 'politics'\n",
      " 'entertainment' 'politics' 'entertainment' 'entertainment' 'politics'\n",
      " 'politics' 'politics' 'politics' 'entertainment' 'politics'\n",
      " 'entertainment' 'entertainment' 'entertainment' 'politics' 'politics'\n",
      " 'politics' 'entertainment' 'politics' 'parenting' 'politics'\n",
      " 'entertainment' 'politics' 'politics' 'entertainment' 'entertainment'\n",
      " 'politics' 'politics' 'politics' 'politics' 'politics' 'politics'\n",
      " 'politics' 'politics' 'politics' 'entertainment' 'politics'\n",
      " 'entertainment' 'entertainment' 'entertainment' 'entertainment'\n",
      " 'politics' 'entertainment' 'entertainment' 'politics' 'politics'\n",
      " 'entertainment' 'entertainment' 'entertainment' 'entertainment'\n",
      " 'entertainment' 'entertainment' 'entertainment' 'politics'\n",
      " 'entertainment' 'politics' 'politics' 'entertainment' 'politics'\n",
      " 'entertainment' 'politics' 'politics' 'entertainment' 'politics'\n",
      " 'entertainment' 'politics' 'politics' 'entertainment' 'entertainment'\n",
      " 'entertainment' 'entertainment' 'entertainment' 'entertainment'\n",
      " 'entertainment' 'politics' 'entertainment' 'entertainment'\n",
      " 'entertainment' 'politics' 'politics' 'politics' 'politics' 'politics'\n",
      " 'entertainment' 'politics' 'politics' 'entertainment' 'politics'\n",
      " 'entertainment' 'entertainment' 'politics' 'politics' 'entertainment'\n",
      " 'entertainment' 'entertainment' 'politics' 'entertainment' 'politics'\n",
      " 'entertainment' 'politics' 'politics' 'entertainment' 'politics'\n",
      " 'entertainment' 'politics' 'politics' 'politics' 'entertainment'\n",
      " 'entertainment' 'entertainment' 'politics' 'politics' 'politics'\n",
      " 'politics' 'politics' 'entertainment' 'politics' 'politics' 'politics'\n",
      " 'politics' 'politics' 'politics' 'entertainment' 'politics'\n",
      " 'entertainment' 'entertainment' 'politics' 'entertainment' 'politics'\n",
      " 'politics' 'entertainment' 'politics' 'entertainment' 'entertainment'\n",
      " 'politics' 'entertainment' 'entertainment' 'entertainment'\n",
      " 'entertainment' 'politics' 'politics' 'politics' 'politics' 'politics'\n",
      " 'entertainment' 'politics' 'politics' 'entertainment' 'politics'\n",
      " 'entertainment' 'entertainment' 'politics' 'entertainment' 'politics'\n",
      " 'entertainment' 'entertainment' 'entertainment' 'politics'\n",
      " 'entertainment' 'entertainment' 'entertainment' 'politics' 'politics'\n",
      " 'politics' 'entertainment' 'politics' 'politics' 'entertainment'\n",
      " 'politics' 'politics' 'entertainment' 'politics' 'entertainment'\n",
      " 'politics' 'politics' 'politics' 'politics' 'entertainment'\n",
      " 'entertainment' 'entertainment' 'entertainment' 'politics' 'politics'\n",
      " 'entertainment' 'entertainment' 'entertainment' 'politics' 'politics'\n",
      " 'entertainment' 'entertainment' 'entertainment' 'entertainment'\n",
      " 'politics' 'politics' 'entertainment' 'entertainment' 'politics'\n",
      " 'politics' 'politics' 'politics' 'entertainment' 'politics' 'politics'\n",
      " 'politics' 'politics' 'politics' 'politics' 'entertainment' 'politics'\n",
      " 'entertainment' 'politics' 'politics' 'politics' 'entertainment'\n",
      " 'entertainment' 'entertainment' 'politics' 'politics' 'politics'\n",
      " 'entertainment' 'entertainment' 'politics' 'politics' 'politics'\n",
      " 'politics' 'entertainment' 'politics' 'politics' 'entertainment'\n",
      " 'entertainment' 'entertainment' 'entertainment' 'entertainment'\n",
      " 'entertainment' 'entertainment' 'politics' 'entertainment' 'politics'\n",
      " 'entertainment' 'entertainment' 'entertainment' 'entertainment'\n",
      " 'entertainment' 'politics' 'politics' 'entertainment' 'politics'\n",
      " 'entertainment' 'entertainment' 'politics' 'politics' 'politics'\n",
      " 'entertainment' 'entertainment' 'entertainment' 'entertainment'\n",
      " 'politics' 'entertainment' 'politics' 'entertainment' 'entertainment'\n",
      " 'entertainment' 'entertainment' 'politics' 'entertainment' 'parenting'\n",
      " 'entertainment' 'politics' 'politics' 'politics' 'politics' 'politics'\n",
      " 'entertainment' 'politics' 'politics' 'politics' 'entertainment'\n",
      " 'entertainment' 'entertainment' 'entertainment' 'politics'\n",
      " 'entertainment' 'entertainment' 'politics' 'entertainment' 'politics'\n",
      " 'politics' 'entertainment' 'politics' 'entertainment' 'entertainment'\n",
      " 'politics' 'entertainment' 'entertainment' 'entertainment'\n",
      " 'entertainment' 'politics' 'politics' 'politics' 'politics'\n",
      " 'entertainment' 'politics' 'entertainment' 'entertainment' 'politics'\n",
      " 'politics' 'entertainment' 'entertainment' 'politics' 'entertainment'\n",
      " 'politics' 'entertainment' 'politics' 'entertainment' 'politics'\n",
      " 'politics' 'politics' 'politics' 'entertainment' 'politics'\n",
      " 'entertainment' 'entertainment' 'entertainment' 'entertainment'\n",
      " 'entertainment' 'entertainment' 'politics' 'politics' 'politics'\n",
      " 'entertainment' 'politics' 'politics' 'politics' 'entertainment'\n",
      " 'politics' 'politics' 'entertainment' 'entertainment' 'entertainment'\n",
      " 'politics' 'entertainment' 'entertainment' 'entertainment'\n",
      " 'entertainment' 'politics' 'entertainment' 'entertainment' 'politics'\n",
      " 'politics' 'entertainment' 'entertainment' 'entertainment'\n",
      " 'entertainment' 'politics' 'entertainment' 'politics' 'entertainment'\n",
      " 'entertainment' 'politics' 'politics' 'politics' 'politics'\n",
      " 'entertainment' 'politics' 'politics' 'entertainment' 'politics'\n",
      " 'entertainment' 'politics' 'entertainment' 'entertainment'\n",
      " 'entertainment' 'entertainment' 'politics' 'entertainment' 'politics'\n",
      " 'politics' 'politics' 'politics' 'entertainment' 'entertainment'\n",
      " 'entertainment' 'politics' 'politics' 'entertainment' 'politics'\n",
      " 'politics' 'politics' 'entertainment' 'entertainment' 'entertainment'\n",
      " 'politics' 'politics' 'travel' 'entertainment' 'politics' 'entertainment'\n",
      " 'politics' 'entertainment' 'politics' 'politics' 'politics'\n",
      " 'entertainment' 'politics' 'politics' 'entertainment' 'politics'\n",
      " 'politics' 'politics' 'politics' 'entertainment' 'politics' 'politics'\n",
      " 'politics' 'politics' 'entertainment' 'politics' 'politics' 'politics'\n",
      " 'politics' 'entertainment' 'politics' 'entertainment' 'entertainment'\n",
      " 'politics' 'politics' 'politics' 'politics' 'politics' 'politics'\n",
      " 'entertainment' 'entertainment' 'politics' 'politics' 'politics'\n",
      " 'politics' 'politics' 'entertainment' 'politics' 'entertainment'\n",
      " 'entertainment' 'entertainment' 'politics' 'entertainment'\n",
      " 'entertainment' 'entertainment' 'entertainment' 'politics'\n",
      " 'entertainment' 'politics' 'politics' 'entertainment' 'politics'\n",
      " 'politics' 'entertainment' 'entertainment' 'entertainment'\n",
      " 'entertainment' 'politics' 'entertainment' 'politics' 'politics'\n",
      " 'politics' 'entertainment' 'politics' 'entertainment' 'politics'\n",
      " 'politics' 'entertainment' 'politics' 'entertainment' 'entertainment'\n",
      " 'politics' 'entertainment' 'politics' 'politics' 'entertainment'\n",
      " 'politics' 'politics' 'politics' 'entertainment' 'entertainment'\n",
      " 'entertainment' 'politics' 'parenting' 'politics' 'entertainment'\n",
      " 'entertainment' 'entertainment' 'politics' 'politics' 'politics'\n",
      " 'politics' 'politics' 'politics' 'entertainment' 'politics' 'politics'\n",
      " 'entertainment' 'politics' 'entertainment' 'politics' 'entertainment'\n",
      " 'politics' 'entertainment' 'entertainment' 'entertainment' 'politics'\n",
      " 'politics' 'politics' 'entertainment' 'entertainment' 'entertainment'\n",
      " 'politics' 'politics' 'entertainment' 'entertainment' 'politics'\n",
      " 'politics' 'politics' 'politics' 'entertainment' 'politics'\n",
      " 'entertainment' 'entertainment' 'politics' 'entertainment' 'politics'\n",
      " 'politics' 'politics' 'entertainment' 'politics' 'politics' 'politics'\n",
      " 'politics' 'entertainment' 'entertainment' 'entertainment' 'politics'\n",
      " 'politics' 'politics' 'politics' 'entertainment' 'entertainment'\n",
      " 'politics' 'politics' 'travel' 'politics' 'entertainment' 'entertainment'\n",
      " 'politics' 'politics' 'politics' 'politics' 'politics' 'politics'\n",
      " 'politics' 'entertainment' 'entertainment' 'politics' 'entertainment'\n",
      " 'politics' 'entertainment' 'politics' 'entertainment' 'politics'\n",
      " 'entertainment' 'entertainment' 'entertainment' 'politics' 'politics'\n",
      " 'politics' 'politics' 'entertainment' 'entertainment' 'entertainment'\n",
      " 'entertainment' 'politics' 'entertainment' 'entertainment'\n",
      " 'entertainment' 'entertainment' 'entertainment' 'entertainment'\n",
      " 'politics' 'entertainment' 'entertainment' 'politics' 'entertainment'\n",
      " 'entertainment' 'entertainment' 'politics']\n",
      "0.8790849673202614\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "testX = np.array(testSet['bagOfWords'].tolist())\n",
    "testY = np.array(testSet['category'].tolist())\n",
    "print(testX.shape, testY.shape)\n",
    "predY = classifier.predict(testX)\n",
    "accuracy = accuracy_score(testY, predY)\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9920a9191bbd0883129cd4e7291d7025cf6acd0cb1f54d8654d4c35c2558a4dd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
